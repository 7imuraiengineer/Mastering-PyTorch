{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset information\n",
    "- There are 240 training images and 150 validation images divided equally between the two classes (bees and ants). \n",
    "- We download the dataset from this link - https://www.kaggle.com/ajayrana/hymenoptera-data and store it in the current working directory. \n",
    "- In order to download the dataset you will need to login to kaggle. If you do not already have a kaggle account, you will need to register.\n",
    "- More information about the dataset can be found here: https://hymenoptera.elsiklab.missouri.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = 'hymenoptera_data'\n",
    "\n",
    "# Data normalization and augmentation transformations for train dataset\n",
    "# Only normalization transformation for validation dataset\n",
    "# The mean and std for normalization are calculated as the mean of all pixel values for all images in the training set per each image channel - R, G and B\n",
    "\n",
    "data_transformers = {\n",
    "    'train': transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])]),\n",
    "    'val': transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), \n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])])}\n",
    "\n",
    "img_data = {k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k]) for k in ['train', 'val']}\n",
    "dloaders = {k: torch.utils.data.DataLoader(img_data[k], batch_size=8, shuffle=True, num_workers=2) \n",
    "            for k in ['train', 'val']}\n",
    "dset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\n",
    "classes = img_data['train'].classes\n",
    "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageshow(img, text=None):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    avg = np.array([0.490, 0.449, 0.411])\n",
    "    stddev = np.array([0.231, 0.221, 0.230])\n",
    "    img = stddev * img + avg\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if text is not None:\n",
    "        plt.title(text)\n",
    "\n",
    "# Generate one train dataset batch\n",
    "imgs, cls = next(iter(dloaders['train']))\n",
    "\n",
    "# Generate a grid from batch\n",
    "grid = torchvision.utils.make_grid(imgs)\n",
    "\n",
    "imageshow(grid, text=[classes[c] for c in cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(pretrained_model, loss_func, optim, epochs=10):\n",
    "    start = time.time()\n",
    "\n",
    "    model_weights = copy.deepcopy(pretrained_model.state_dict())\n",
    "    accuracy = 0.0\n",
    "\n",
    "    for e in range(epochs):\n",
    "        print(f'Epoch number {e}/{epochs - 1}')\n",
    "        print('=' * 20)\n",
    "\n",
    "        # for each epoch we run through the training and validation set\n",
    "        for dset in ['train', 'val']:\n",
    "            if dset == 'train':\n",
    "                pretrained_model.train()  # set model to train mode (i.e. trainbale weights)\n",
    "            else:\n",
    "                pretrained_model.eval()   # set model to validation mode\n",
    "\n",
    "            loss = 0.0\n",
    "            successes = 0\n",
    "\n",
    "            # iterate over the (training/validation) data.\n",
    "            for imgs, tgts in dloaders[dset]:\n",
    "                imgs = imgs.to(dvc)\n",
    "                tgts = tgts.to(dvc)\n",
    "                optim.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(dset == 'train'):\n",
    "                    ops = pretrained_model(imgs)\n",
    "                    _, preds = torch.max(ops, 1)\n",
    "                    loss_curr = loss_func(ops, tgts)\n",
    "                    # backward pass only if in training mode\n",
    "                    if dset == 'train':\n",
    "                        loss_curr.backward()\n",
    "                        optim.step()\n",
    "\n",
    "                loss += loss_curr.item() * imgs.size(0)\n",
    "                successes += torch.sum(preds == tgts.data)\n",
    "\n",
    "            loss_epoch = loss / dset_sizes[dset]\n",
    "            accuracy_epoch = successes.double() / dset_sizes[dset]\n",
    "\n",
    "            print(f'{dset} loss in this epoch: {loss_epoch}, accuracy in this epoch: {accuracy_epoch}')\n",
    "            if dset == 'val' and accuracy_epoch > accuracy:\n",
    "                accuracy = accuracy_epoch\n",
    "                model_weights = copy.deepcopy(pretrained_model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_delta = time.time() - start\n",
    "    print(f'Training finished in {time_delta // 60}mins {time_delta % 60}secs')\n",
    "    print(f'Best validation set accuracy: {accuracy}')\n",
    "\n",
    "    # load the best model version (weights)\n",
    "    pretrained_model.load_state_dict(model_weights)\n",
    "    return pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(pretrained_model, max_num_imgs=4):\n",
    "    torch.manual_seed(1)\n",
    "    was_model_training = pretrained_model.training\n",
    "    pretrained_model.eval()\n",
    "    imgs_counter = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, tgts) in enumerate(dloaders['val']):\n",
    "            imgs = imgs.to(dvc)\n",
    "            tgts = tgts.to(dvc)\n",
    "            ops = pretrained_model(imgs)\n",
    "            _, preds = torch.max(ops, 1)\n",
    "            \n",
    "            for j in range(imgs.size()[0]):\n",
    "                imgs_counter += 1\n",
    "                ax = plt.subplot(max_num_imgs//2, 2, imgs_counter)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'pred: {classes[preds[j]]} || target: {classes[tgts[j]]}')\n",
    "                imageshow(imgs.cpu().data[j])\n",
    "\n",
    "                if imgs_counter == max_num_imgs:\n",
    "                    pretrained_model.train(mode=was_model_training)\n",
    "                    return\n",
    "        pretrained_model.train(mode=was_model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetune = models.alexnet(pretrained=True) \n",
    "print(model_finetune.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_finetune.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the last layer from 1000 classes to 2 classes\n",
    "model_finetune.classifier[6] = nn.Linear(4096, len(classes))\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim_finetune = optim.SGD(model_finetune.parameters(), lr=0.0001)\n",
    "\n",
    "# train (fine-tune) and validate the model\n",
    "model_finetune = finetune_model(model_finetune, loss_func, optim_finetune, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model_finetune)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
